{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "done = 0\n",
    "data = {}\n",
    "for f in listdir('data'):\n",
    "    data[f[:-2]] = pickle.load(open('data/' + f, 'rb'), encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "735\n",
      "222\n",
      "148\n",
      "108\n",
      "1847\n",
      "189\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "for i in data:\n",
    "    print(len(data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.nn.rnn_cell import LSTMCell\n",
    "import tensorflow.layers\n",
    "\n",
    "class LSTM:\n",
    "    def __init__(self):\n",
    "        rnn_layers = [tf.nn.rnn_cell.LSTMCell(x) for x in [128, 128, 1]]\n",
    "        self.lstm = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
    "        self.inp = tf.placeholder(tf.uint8, shape=[None, 20], name='in')\n",
    "        self.data = tf.one_hot(self.inp, depth=4)\n",
    "        self.labels = tf.placeholder(tf.float32, shape=[None, 1], name='labels')\n",
    "        self.results, _ = tf.nn.dynamic_rnn(self.lstm, self.data, dtype=tf.float32)\n",
    "        self.loss = tf.reduce_mean(tf.squared_difference(self.results, self.labels))\n",
    "        self.op = tf.train.AdamOptimizer(0.001).minimize(self.loss)\n",
    "    def train(self, sess, seq, labels):\n",
    "        loss, _ = sess.run([self.loss, self.op], \n",
    "                           feed_dict={self.inp: seq, self.labels: labels})\n",
    "        return loss\n",
    "    def evaluate(self, sess, seq, labels):\n",
    "        loss = sess.run(self.loss, \n",
    "                           feed_dict={self.inp: seq, self.labels: labels})\n",
    "        return loss\n",
    "    def run(self, sess, seq):\n",
    "        results = sess.run(self.results, \n",
    "                           feed_dict={self.inp: seq})\n",
    "        return results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_p = 0.5\n",
    "val_n = 0.0\n",
    "\n",
    "pA=[('A' * 20, val_p)],\n",
    "pB=[('T' * 20, val_p)],\n",
    "pC=[('C' * 20, val_p)],\n",
    "pD=[('G' * 20, val_p)],\n",
    "nA=[('A' * 20, val_n)],\n",
    "nB=[('T' * 20, val_n)],\n",
    "nC=[('C' * 20, val_n)],\n",
    "nD=[('G' * 20, val_n)],\n",
    "\n",
    "toy_env = dict(\n",
    "    tA = 5 * nA + 5 * nB + 10 * pA,\n",
    "    tB = 5 * pC + 5 * pB + 10 * nD,\n",
    "    tC = 5 * pA + 5 * pD + 5 * nC + 5 * nB,\n",
    "    tD = 5 * nA + 5 * nB + 10 * pA,\n",
    "    tE = 5 * pC + 5 * pB + 10 * nD,\n",
    "    vA = 5 * pA + 5 * pD + 5 * nC + 5 * nB,\n",
    "    vB = 5 * pA + 5 * pD + 5 * nC + 5 * nB,\n",
    "    vC = 5 * pC + 5 * pB + 10 * nD,\n",
    ")\n",
    "data = {}\n",
    "for x in toy_env:\n",
    "    data[x] = [i[0] for i in toy_env[x]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = [x for x in data]\n",
    "train = genes[:5]\n",
    "validate = genes[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "net = LSTM()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec(s):\n",
    "    return np.array(['ATCG'.index(x) for x in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tqdm\n",
    "from random import *\n",
    "import numpy as np\n",
    "def training():\n",
    "    loss = []\n",
    "    pbar = tqdm(list(range(2000)))\n",
    "    for i in pbar:\n",
    "        train_data = data[choice(train)]\n",
    "        shuffle(train_data)\n",
    "        sample = train_data[:20]\n",
    "        values = np.array([vec(x[0]) for x in sample])\n",
    "        labels = np.array([[x[1]] for x in sample])\n",
    "        loss.append(net.train(sess, values, labels))\n",
    "\n",
    "    return np.mean(np.array(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation():\n",
    "    loss = []\n",
    "    pbar = tqdm(list(range(500)))\n",
    "    for i in pbar:\n",
    "        train_data = data[choice(validate)]\n",
    "        shuffle(train_data)\n",
    "        sample = train_data[:20]\n",
    "        values = np.array([vec(x[0]) for x in sample])\n",
    "        labels = np.array([[x[1]] for x in sample])\n",
    "        loss.append(net.evaluate(sess, values, labels))\n",
    "\n",
    "    return np.mean(np.array(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-648c917fe13c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mloss_t\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mloss_v\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-cfec0114b326>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-fb63ba2ad2d1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sess, seq, labels)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         loss, _ = sess.run([self.loss, self.op], \n\u001b[0;32m---> 22\u001b[0;31m                            feed_dict={self.inp: res, self.labels: labels})\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Programming/234-dna/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Programming/234-dna/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m~/Documents/Programming/234-dna/venv/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss_t = []\n",
    "loss_v = []\n",
    "for i in range(6):\n",
    "    loss_t += [training()]\n",
    "    loss_v += [validation()]\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.plot(np.array(loss_t), label='training')\n",
    "plt.plot(np.array(loss_v), label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]],\n",
       "\n",
       "       [[0.25172085],\n",
       "        [0.25115234],\n",
       "        [0.2522114 ],\n",
       "        [0.24931656],\n",
       "        [0.24883813],\n",
       "        [0.24800994],\n",
       "        [0.24779543],\n",
       "        [0.24757418],\n",
       "        [0.24749605],\n",
       "        [0.24743049],\n",
       "        [0.24740025],\n",
       "        [0.24737744],\n",
       "        [0.2473646 ],\n",
       "        [0.24735531],\n",
       "        [0.24734937],\n",
       "        [0.24734512],\n",
       "        [0.24734223],\n",
       "        [0.2473401 ],\n",
       "        [0.24733864],\n",
       "        [0.24733754]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.run(sess, np.array([vec('A' * 20) for x in range(20)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "py3.6env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
