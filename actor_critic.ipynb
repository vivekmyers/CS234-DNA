{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "done = 0\n",
    "data = {}\n",
    "for f in listdir('data'):\n",
    "    data[f[:-2]] = pickle.load(open('data/' + f, 'rb'), encoding='latin1')\n",
    "\n",
    "genes = [x for x in data]\n",
    "training = genes[:5]\n",
    "testing = genes[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "val_p = 1\n",
    "val_n = 0\n",
    "\n",
    "pA=[('A' * 20, val_p)],\n",
    "pB=[('T' * 20, val_p)],\n",
    "pC=[('C' * 20, val_p)],\n",
    "pD=[('G' * 20, val_p)],\n",
    "nA=[('A' * 20, val_n)],\n",
    "nB=[('T' * 20, val_n)],\n",
    "nC=[('C' * 20, val_n)],\n",
    "nD=[('G' * 20, val_n)],\n",
    "\n",
    "toy_env = dict(\n",
    "    tB = (5 * pC + 5 * pB + 10 * nD) * 10,\n",
    "    tC = (5 * pA + 5 * pD + 5 * nC + 5 * nB) * 10,\n",
    "    tD = (5 * nD + 5 * nB + 10 * pA) * 10,\n",
    "    vB = (5 * pA + 5 * pD + 5 * nC + 5 * nB) * 10,\n",
    "    tE = (5 * pC + 5 * pB + 10 * nD) * 10,\n",
    "    vA = (5 * pA + 5 * pD + 5 * nC + 5 * nB) * 10,\n",
    "    vC = (5 * pC + 5 * pB + 10 * nD) * 10,\n",
    "    tA = (5 * nC + 5 * nB + 10 * pA) * 10,\n",
    ")\n",
    "data = {}\n",
    "for x in toy_env:\n",
    "    data[x] = [i[0] for i in toy_env[x]]\n",
    "    \n",
    "genes = [x for x in data]\n",
    "random.shuffle(genes)\n",
    "training = genes[:5]\n",
    "testing = genes[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "eps = 0.00001\n",
    "\n",
    "class SeqNet:\n",
    "    def __init__(self, seq_len=20, ktop=5, lr=0.0001, gamma=0.8, horizon=20):\n",
    "        '''\n",
    "        ktop is size of memory buffer, lr learning rate, and horizon number of iterations\n",
    "        per episode.\n",
    "        '''\n",
    "        self.gamma = gamma\n",
    "        self.seq_len = seq_len\n",
    "        self.ktop = ktop\n",
    "        self.lr = lr\n",
    "        self.horizon = horizon\n",
    "        self.sess = tf.Session()\n",
    "        self.build_placeholders()\n",
    "        self.build_network()\n",
    "        self.make_train_ops()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.writer = tf.summary.FileWriter('results', self.sess.graph)\n",
    "\n",
    "    def build_placeholders(self):\n",
    "        self.actions = tf.placeholder(tf.float32, shape=[None, self.seq_len, 4], name='actions')\n",
    "        self.sequences = tf.placeholder(tf.float32, shape=[None, self.seq_len * self.ktop, 4], name='sequences')\n",
    "        self.returns = tf.placeholder(tf.float32, shape=[None], name='returns')\n",
    "        self.on_target_labels = tf.placeholder(tf.float32, shape=[None, self.ktop], name='on_target_labels')\n",
    "        self.static_advantages = tf.placeholder(tf.float32, shape=[None], name='static_advantages')\n",
    "\n",
    "    def build_network(self):\n",
    "        self.conv1 = tf.layers.conv1d(inputs=self.sequences, filters=80,\n",
    "                                      kernel_size=7, activation=tf.nn.relu)\n",
    "        self.conv2 = tf.layers.conv1d(inputs=self.conv1, filters=80,\n",
    "                                      kernel_size=7, activation=tf.nn.relu)\n",
    "        self.conv3 = tf.layers.conv1d(inputs=self.conv2, filters=80,\n",
    "                                      kernel_size=1, activation=tf.nn.relu)\n",
    "        self.merged = tf.concat([tf.layers.flatten(self.conv3),\n",
    "                                 self.on_target_labels], axis=1)\n",
    "        self.dense1_actor = tf.layers.dense(inputs=self.merged, units=512,\n",
    "                                            activation=tf.nn.relu)\n",
    "        self.dense2_actor = tf.layers.dense(inputs=self.dense1_actor, units=self.seq_len * 4)\n",
    "        self.dense1_critic = tf.layers.dense(inputs=self.merged, units=512,\n",
    "                                             activation=tf.nn.relu)\n",
    "        self.dense2_critic = tf.layers.dense(self.dense1_critic, units=1)\n",
    "\n",
    "        self.output_seq = tf.reshape(self.dense2_actor, [-1, self.seq_len, 4])\n",
    "        self.sample_output_seq = tf.reshape(tf.one_hot(\n",
    "            tf.reshape(\n",
    "                tf.multinomial(tf.reshape(self.output_seq, [-1, 4]), 1),\n",
    "                shape=[-1, self.seq_len]),\n",
    "            depth=4), [-1, self.seq_len, 4])\n",
    "        self.logprob = tf.reduce_sum(\n",
    "            -tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                labels=self.actions, logits=self.output_seq), axis=1)\n",
    "        self.baseline = tf.squeeze(self.dense2_critic, axis=1)\n",
    "        self.advantage = self.returns - self.baseline\n",
    "\n",
    "    def make_train_ops(self):\n",
    "        self.actor_loss = tf.reduce_mean(-self.logprob * self.static_advantages)\n",
    "        self.train_actor = tf.train.AdamOptimizer(self.lr).minimize(self.actor_loss)\n",
    "        self.critic_loss = tf.reduce_mean(tf.squared_difference(self.returns, self.baseline))\n",
    "        self.train_critic = tf.train.AdamOptimizer(self.lr).minimize(self.critic_loss)\n",
    "\n",
    "    def get_advantages(self, seqs, r_ktops, actions, returns):\n",
    "        return self.sess.run(self.advantage, feed_dict={\n",
    "            self.actions: list(actions),\n",
    "            self.sequences: list(seqs),\n",
    "            self.returns: list(returns),\n",
    "            self.on_target_labels: list(r_ktops),\n",
    "        })\n",
    "\n",
    "    def improve(self, seqs, r_ktop, actions, rewards):\n",
    "        '''\n",
    "        Policy gradient update in both actor and critic\n",
    "        '''\n",
    "        returns = [sum((self.gamma ** (i - j)) * rewards[i]\n",
    "                       for i in range(j, len(rewards)))\n",
    "                   for j, _ in enumerate(rewards)]\n",
    "        adv = self.get_advantages(seqs, r_ktop, actions, returns)\n",
    "        adv = np.array(adv)\n",
    "        adv = (adv - np.mean(adv)) / (np.std(adv) + eps)\n",
    "        cl, _ = self.sess.run([self.critic_loss, self.train_critic], feed_dict={\n",
    "            self.actions: actions,\n",
    "            self.sequences: seqs,\n",
    "            self.returns: returns,\n",
    "            self.on_target_labels: r_ktop,\n",
    "        })\n",
    "        al, _ = self.sess.run([self.actor_loss, self.train_actor], feed_dict={\n",
    "            self.static_advantages: adv,\n",
    "            self.actions: actions,\n",
    "            self.sequences: seqs,\n",
    "            self.returns: returns,\n",
    "            self.on_target_labels: r_ktop,\n",
    "        })\n",
    "\n",
    "    def run(self, seqs, rewards):\n",
    "        return np.squeeze(self.sess.run(self.sample_output_seq, feed_dict={\n",
    "            self.sequences: np.array([seqs]),\n",
    "            self.on_target_labels: np.array([rewards]),\n",
    "        }))\n",
    "    \n",
    "    def flat(self, state):\n",
    "        return np.reshape(state, [state.shape[0] * state.shape[1], 4])\n",
    "\n",
    "    def path(self, samples):\n",
    "        '''\n",
    "        Get states, actions, and rewards of trajectory in given sample space. Rewards are scaled down\n",
    "        based on L1 distance to valid sequence.\n",
    "        '''\n",
    "        samples = samples[:]\n",
    "        state = random.sample(samples, self.ktop)\n",
    "        for x in state:\n",
    "            for i, v in enumerate(samples):\n",
    "                if (v[0] == x[0]).all():\n",
    "                    del samples[i]\n",
    "                    break\n",
    "        visited = state[:]\n",
    "        path = []\n",
    "        for i in range(self.horizon):\n",
    "            if not samples:\n",
    "                break\n",
    "            seqs, rewards = [np.array(i) for i in zip(*state)]\n",
    "            action = self.run(self.flat(seqs), rewards)\n",
    "            d = lambda x: sum((x[0][i] != action[i]).any() for i, _ in enumerate(x[0]))\n",
    "            new_seq, reward = min(samples, key=d)\n",
    "            for i, v in enumerate(samples):\n",
    "                if (v[0] == new_seq).all():\n",
    "                    del samples[i]\n",
    "                    break\n",
    "            visited.append((new_seq, reward))\n",
    "            path.append((state, action, reward * (1 - d((new_seq, reward)) / self.seq_len)))\n",
    "            state = sorted(visited, key=lambda x: -x[1])[:self.ktop]\n",
    "        return zip(*path)\n",
    "\n",
    "    def train(self, samples, iterations):\n",
    "        '''\n",
    "        Trains on samples (list of one-hot dna strand, on-target rate tuples) and returns avg reward\n",
    "        '''\n",
    "        results = []\n",
    "        for i in range(iterations):\n",
    "            states, actions, rewards = self.path(samples)\n",
    "            for k, i, j in list(zip(states, actions, rewards)):\n",
    "                results.append(j)\n",
    "            seqs = np.array([[v[0] for v in x] for x in states])\n",
    "            labels = np.array([[v[1] for v in x] for x in states])\n",
    "            self.improve(np.reshape(seqs, [seqs.shape[0], \n",
    "                                           seqs.shape[1] * seqs.shape[2], 4]), \n",
    "                                             labels, actions, rewards)\n",
    "        return np.mean(np.array(results))\n",
    "            \n",
    "    def evaluate(self, samples, iterations):\n",
    "        '''\n",
    "        Runs on samples and returns avg reward\n",
    "        '''\n",
    "        rewards = []\n",
    "        for i in range(iterations):\n",
    "            s, a, r = net.path(samples)\n",
    "            for k, i, j in list(zip(s, a, r)):\n",
    "                rewards.append(j)\n",
    "        return np.mean(np.array(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SeqNet(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dna_vec(s):\n",
    "    mask = np.array(['ATCG'.index(i) for i in s])\n",
    "    arr = np.zeros([len(s), 4])\n",
    "    arr[np.arange(len(s)), mask] = 1\n",
    "    return arr\n",
    "\n",
    "def vec_dna(v):\n",
    "    return ''.join(['ATCG'[np.argmax(i)] for i in v])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "0.308\n",
      "0.86425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:47<07:04, 47.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30924999999999997\n",
      "------------------------------\n",
      "------------------------------\n",
      "0.30174999999999996\n",
      "0.8445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [01:31<06:09, 46.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29975\n",
      "------------------------------\n",
      "------------------------------\n",
      "0.314\n",
      "0.85775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [02:19<05:27, 46.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2925\n",
      "------------------------------\n",
      "------------------------------\n",
      "0.309\n",
      "0.8427500000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [03:05<04:39, 46.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29950000000000004\n",
      "------------------------------\n",
      "------------------------------\n",
      "0.32175\n",
      "0.77875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [03:49<03:49, 45.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32475000000000004\n",
      "------------------------------\n",
      "------------------------------\n",
      "0.35125\n",
      "0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [04:35<03:02, 45.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35074999999999995\n",
      "------------------------------\n",
      "------------------------------\n",
      "0.36024999999999996\n",
      "0.7954999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [05:19<02:15, 45.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38125\n",
      "------------------------------\n",
      "------------------------------\n",
      "0.38525\n",
      "0.8379999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [06:03<01:30, 45.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39175\n",
      "------------------------------\n",
      "------------------------------\n",
      "0.43150000000000005\n",
      "0.8322499999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [06:47<00:44, 44.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43575\n",
      "------------------------------\n",
      "------------------------------\n",
      "0.49825\n",
      "0.7732499999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 10/10 [07:31<00:00, 44.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48325\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in trange(10):\n",
    "    for i in training:\n",
    "        net.train([(dna_vec(a), b) for a, b in data[i]], 10)\n",
    "    print('-' * 30)\n",
    "    for i in testing:\n",
    "        print(net.evaluate([(dna_vec(a), b) for a, b in data[i]], 10))\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATCCAATTACAATACATATT 0.35\n",
      "TTCTTATTAATATACATATA 0.5\n",
      "TTTTTATAAATATCTACCTT 0.55\n",
      "TCTACATTAATATCCCTCTT 0.44999999999999996\n",
      "ATCACATCAATATACTTTAT 0.4\n",
      "TTCTCCTTAATATACTTCAT 0.5\n",
      "TTTTTATAAATATATATCTT 0.6\n",
      "TTCGTATTAATCTCTATATT 0.55\n",
      "TTCTTATCATACTCAATATT 0.5\n",
      "TTCGCGTCATTATCTTTATT 0.55\n",
      "TTATTCTTATTATACATTTT 0.65\n",
      "TTCTAATCAATATCCATTTT 0.5\n",
      "TTCATACTAATACCCACCTT 0.35\n",
      "CTCCCAGCATTATCTATTTT 0.44999999999999996\n",
      "TTCTCATTAATATCCAAATT 0.44999999999999996\n",
      "TTCTTCTTAACATCTACTTT 0.55\n",
      "TTTTAATTCCTATCCTTACT 0.55\n",
      "TTTAAATTAATCTCCTTAAT 0.5\n",
      "TTTAATTTAATATATTTATT 0.65\n",
      "TTCTTCTTATTATACATCAT 0.55\n",
      "--------------------------------------------------\n",
      "TTAAAATAAATATATACAAT 0.6\n",
      "TTCAAAATAAAATAAACAAA 0.7\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "ATAAAAAAAAAATAAACAAA 0.85\n",
      "--------------------------------------------------\n",
      "TTTGAATTATGATAATTCTT 0.55\n",
      "TTCTTCTTAATCTCATCCTT 0.55\n",
      "CTTGCGTTAATCTCCATAAT 0.4\n",
      "ATCATATTAATATCCTTCTT 0.5\n",
      "TTCTAATCACTATACAAATT 0.4\n",
      "TTTATTTCATTCTCCATATT 0.6\n",
      "TTGTTGCTAATATCCATTTT 0.55\n",
      "ATTGTATTAATCTCCATATT 0.5\n",
      "TTATTCTTAATCTCTTTCTT 0.65\n",
      "TTCATATTAATATCCATATT 0.5\n",
      "TTTTCATTATTCGCGCTTTT 0.6\n",
      "TTTTTATTCATATCTTTCTT 0.7\n",
      "TTCTCCTTAATATCCACATT 0.44999999999999996\n",
      "TTTCTCTTATTCTACTTATT 0.65\n",
      "TTCACGTTATTATCTTTATT 0.6\n",
      "TTCCTATTAATATCCTCCTT 0.5\n",
      "TTCTAATCCTTCTACTTATT 0.55\n",
      "TTTCTATTATTATACATTTT 0.65\n",
      "CTCGAATTCTGATACATCTT 0.4\n",
      "TTTTTATTCTTATCCATATT 0.65\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in testing:\n",
    "    s, a, r = (net.path([(dna_vec(a), b) for a, b in data[i]]))\n",
    "    for x, y in zip(a, r):\n",
    "        print(vec_dna(x), y)\n",
    "    print('-' * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "py3.6env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
